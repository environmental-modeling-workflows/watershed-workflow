{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: mesh a delineated watershed\n",
    "\n",
    "Here we mesh the [Coweeta Hydrologic Laboratory](https://www.srs.fs.usda.gov/coweeta/) as an example of how to pull data in from default locations and generate a fully functional ATS mesh.\n",
    "\n",
    "This might be the worst example to use to learn how to use Watershed Workflows.  But it is useful to demonstrate the breadth of problems this project was intended to solve.\n",
    "\n",
    "This includes a range of datasets:\n",
    "\n",
    "* NHD Plus for river network\n",
    "* NRCS soils data for soil types\n",
    "* NLCD for land cover/transpiration/rooting depths\n",
    "* NED for elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib osx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as pcm\n",
    "import shapely\n",
    "import logging\n",
    "\n",
    "import workflow\n",
    "import workflow.source_list\n",
    "import workflow.ui\n",
    "import workflow.colors\n",
    "import workflow.condition\n",
    "import workflow.mesh\n",
    "import workflow.split_hucs\n",
    "\n",
    "workflow.ui.setup_logging(1,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources and setup\n",
    "\n",
    "Next we set up the source watershed and coordinate system and all data sources for our mesh.  We will use the CRS that is included in the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:31,646 - root - INFO: \n",
      "2020-05-13 17:22:31,648 - root - INFO: Meshing shape: ../data/hydrologic_units/others/Coweeta/coweeta_basin.shp\n",
      "2020-05-13 17:22:31,650 - root - INFO: ==============================\n",
      "2020-05-13 17:22:31,651 - root - INFO: \n",
      "2020-05-13 17:22:31,652 - root - INFO: Preprocessing Shapes\n",
      "2020-05-13 17:22:31,653 - root - INFO: ------------------------------\n",
      "2020-05-13 17:22:31,656 - root - INFO: loading file: \"../data/hydrologic_units/others/Coweeta/coweeta_basin.shp\"\n",
      "/Users/uec/codes/anaconda/3/envs/ats_meshing_20190719/lib/python3.7/site-packages/fiona/collection.py:336: FionaDeprecationWarning: Collection slicing is deprecated and will be disabled in a future version.\n",
      "  return self.session.__getitem__(item)\n"
     ]
    }
   ],
   "source": [
    "# specify the input shapefile and a hint as to what HUC it is in.\n",
    "coweeta_shapefile = '../data/hydrologic_units/others/Coweeta/coweeta_basin.shp'\n",
    "hint = '0601'  # hint: HUC 4 containing this shape.  \n",
    "               # This is necessary to avoid downloading all HUCs to search for this shape\n",
    "simplify = 100 # length scale to target average edge\n",
    "\n",
    "logging.info(\"\")\n",
    "logging.info(\"Meshing shape: {}\".format(coweeta_shapefile))\n",
    "logging.info(\"=\"*30)\n",
    "\n",
    "# get the shape and crs of the shape\n",
    "crs, coweeta = workflow.get_split_form_shapes(coweeta_shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wide range of data sources are available; here we use the defaults except for using NHD Plus for watershed boundaries and hydrography (the default is NHD, which is lower resolution and therefore smaller download sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:31,736 - root - INFO: Using sources:\n",
      "2020-05-13 17:22:31,737 - root - INFO: --------------\n",
      "2020-05-13 17:22:31,740 - root - INFO: HUC: National Hydrography Dataset Plus High Resolution (NHDPlus HR)\n",
      "2020-05-13 17:22:31,744 - root - INFO: hydrography: National Hydrography Dataset Plus High Resolution (NHDPlus HR)\n",
      "2020-05-13 17:22:31,747 - root - INFO: DEM: National Elevation Dataset (NED)\n",
      "2020-05-13 17:22:31,749 - root - INFO: soil type: National Resources Conservation Service Soil Survey (NRCS Soils)\n",
      "2020-05-13 17:22:31,751 - root - INFO: land cover: National Land Cover Database (NLCD) Layer: NLCD_2016_Land_Cover_L48\n",
      "2020-05-13 17:22:31,751 - root - INFO: soil thickness: None\n",
      "2020-05-13 17:22:31,752 - root - INFO: meteorology: DayMet 1km\n"
     ]
    }
   ],
   "source": [
    "# set up a dictionary of source objects\n",
    "sources = workflow.source_list.get_default_sources()\n",
    "sources['HUC'] = workflow.source_list.huc_sources['NHD Plus']\n",
    "sources['hydrography'] = workflow.source_list.hydrography_sources['NHD Plus']\n",
    "workflow.source_list.log_sources(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the surface mesh\n",
    "\n",
    "First we'll generate the flattened, 2D triangulation, which builds on hydrography data.  Then we download a digital elevation map from the National Elevation Dataset, and extrude that 2D triangulation to a 3D surface mesh based on interpolation between pixels of the DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = False\n",
    "if rivers:\n",
    "    # download/collect the river network within that shape's bounds\n",
    "    _, reaches = workflow.get_reaches(sources['hydrography'], hint, \n",
    "                                      coweeta.exterior().bounds, crs)\n",
    "    # simplify and prune rivers not IN the shape, constructing a tree-like data structure\n",
    "    # for the river network\n",
    "    rivers = workflow.simplify_and_prune(coweeta, reaches, simplify=simplify, cut_intersections=True)\n",
    "\n",
    "else:\n",
    "    rivers = list()\n",
    "    workflow.split_hucs.simplify(coweeta, simplify)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:31,816 - root - INFO: \n",
      "2020-05-13 17:22:31,818 - root - INFO: Meshing\n",
      "2020-05-13 17:22:31,823 - root - INFO: ------------------------------\n",
      "2020-05-13 17:22:31,825 - root - INFO: Triangulating...\n",
      "2020-05-13 17:22:31,838 - root - INFO:    27 points and 27 facets\n",
      "2020-05-13 17:22:31,839 - root - INFO:  checking graph consistency\n",
      "2020-05-13 17:22:31,841 - root - INFO:  building graph data structures\n",
      "2020-05-13 17:22:31,843 - root - INFO:  triangle.build...\n",
      "2020-05-13 17:22:31,850 - root - INFO:   ...built: 153 mesh points and 256 triangles\n",
      "2020-05-13 17:22:31,851 - root - INFO: Plotting triangulation diagnostics\n",
      "2020-05-13 17:22:31,869 - root - INFO:   min area = 24107.691467285156\n"
     ]
    }
   ],
   "source": [
    "# form a triangulation on the shape + river network\n",
    "\n",
    "# triangulation refinement:\n",
    "# Refine triangles if their area (in m^2) is greater than A(d), where d is the \n",
    "# distance from the triangle centroid to the nearest stream.\n",
    "# A(d) is a piecewise linear function -- A = A0 if d <= d0, A = A1 if d >= d1, and\n",
    "# linearly interpolates between the two endpoints.\n",
    "d0 = 100; d1 = 500\n",
    "A0 = 1000; A1 = 5000\n",
    "#A0 = 500; A1 = 2500\n",
    "#A0 = 100; A1 = 500\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 32 # degrees\n",
    "\n",
    "# make 2D mesh\n",
    "#mesh_points2, mesh_tris, d = workflow.triangulate(coweeta, rivers, \n",
    "#                                               refine_distance=[d0,A0,d1,A1],\n",
    "#                                               refine_min_angle=min_angle,\n",
    "#                                               enforce_delaunay=True,\n",
    "#                                               diagnostics=True)\n",
    "mesh_points2, mesh_tris, d = workflow.triangulate(coweeta, rivers,\n",
    "                                                 refine_max_area=100000,\n",
    "                                                 enforce_delaunay=True,\n",
    "                                                 diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:32,060 - root - INFO: \n",
      "2020-05-13 17:22:32,061 - root - INFO: Preprocessing Raster\n",
      "2020-05-13 17:22:32,061 - root - INFO: ------------------------------\n",
      "2020-05-13 17:22:32,062 - root - INFO: collecting raster\n",
      "2020-05-13 17:22:32,064 - root - INFO: Collecting DEMs to tile bounds: [-83.48845037186388, 35.01734099944037, -83.41165773504302, 35.08381933600275]\n",
      "2020-05-13 17:22:32,066 - root - INFO:   Need:\n",
      "2020-05-13 17:22:32,067 - root - INFO:     /Users/uec/research/water/data/watershed-workflow/data-master/dem/USGS_NED_1as_n36_w084.img\n",
      "2020-05-13 17:22:32,124 - root - INFO: \n",
      "2020-05-13 17:22:32,126 - root - INFO: Elevating Triangulation to DEM\n",
      "2020-05-13 17:22:32,128 - root - INFO: ------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get a raster for the elevation map\n",
    "dem_profile, dem = workflow.get_raster_on_shape(sources['DEM'], coweeta.exterior(), crs)\n",
    "\n",
    "# elevate the triangle nodes to the dem\n",
    "mesh_points3 = workflow.elevate(mesh_points2, crs, dem, dem_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting mesh can be done in a variety of ways, including both 3D plots and mapview.  We show both here, but hereafter use mapview plots as they are a bit clearer (if not so flashy)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6,6)\n",
    "figsize_3d = (8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the resulting surface mesh\n",
    "fig = plt.figure(figsize=figsize_3d)\n",
    "ax = workflow.plot.get_ax('3d', fig, window=[0.0,0.2,1,0.8])\n",
    "cax = fig.add_axes([0.23,0.18,0.58,0.03])\n",
    "\n",
    "mp = ax.plot_trisurf(mesh_points3[:,0], mesh_points3[:,1], mesh_points3[:,2], \n",
    "                     triangles=mesh_tris, cmap='viridis', \n",
    "                     edgecolor=(0,0,0,.2), linewidth=0.5)\n",
    "cb = fig.colorbar(mp, orientation=\"horizontal\", cax=cax)\n",
    "\n",
    "rivers_2 = [np.array(r.xy) for riv in rivers for r in riv]\n",
    "rivers_e = [workflow.values_from_raster(r.transpose(), crs, dem, dem_profile) \n",
    "               for r in rivers_2]\n",
    "rivers_l3 = [np.array([i[0], i[1], j]).transpose() \n",
    "               for i,j in zip(rivers_2, rivers_e)]\n",
    "for r in rivers_l3:\n",
    "    ax.plot(r[:,0]+1, r[:,1], r[:,2]+10, color='red', linewidth=3)\n",
    "\n",
    "t = cax.set_title('elevation [m]')\n",
    "ax.view_init(55,0)\n",
    "ax.set_xticklabels(list())\n",
    "ax.set_yticklabels(list())\n",
    "\n",
    "#fig.savefig('coweeta_dem_3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'elevation [m]')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the resulting surface mesh\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = workflow.plot.get_ax(crs, fig)\n",
    "\n",
    "mp = workflow.plot.triangulation(mesh_points3, mesh_tris, crs, ax=ax, \n",
    "                                 color='elevation', edgecolor='gray', linewidth=0.2)\n",
    "cbar = fig.colorbar(mp, orientation=\"horizontal\", pad=0.05)\n",
    "workflow.plot.hucs(coweeta, crs, ax=ax, color='k', linewidth=1)\n",
    "workflow.plot.rivers(rivers, crs, ax=ax, color='red', linewidth=1)\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "ax.set_title('elevation [m]')\n",
    "cbar.ax.set_title('elevation [m]')\n",
    "#fig.savefig('coweeta_dem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the 2D mesh\n",
    "m2 = workflow.mesh.Mesh2D(mesh_points3.copy(), list(mesh_tris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff =  59.41045465459604\n"
     ]
    }
   ],
   "source": [
    "# hydrologically condition the mesh\n",
    "workflow.condition.condition(m2)\n",
    "\n",
    "# plot the change between the two meshes\n",
    "diff = np.copy(mesh_points3)\n",
    "diff[:,2] = m2.points[:,2] - mesh_points3[:,2] \n",
    "print(\"max diff = \", np.abs(diff[:,2]).max())\n",
    "fig, ax = workflow.plot.get_ax(crs, figsize=figsize)\n",
    "workflow.plot.triangulation(diff, m2.conn, crs, color='elevation', edgecolors='gray', \n",
    "                            linewidth=0.2, ax=ax)\n",
    "ax.set_title('conditioned dz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:32,800 - root - INFO: Constructing Mesh2D as dual of a triangulation.\n",
      "2020-05-13 17:22:32,802 - root - INFO: -- confirming triangulation (note, not checking delaunay, buyer beware)\n",
      "2020-05-13 17:22:32,803 - root - INFO: -- computing primary boundary edges\n",
      "2020-05-13 17:22:32,804 - root - INFO:      n_primal_cell = 256, n_boundary_edges = 48, n_dual_nodes = 352\n",
      "2020-05-13 17:22:32,805 - root - INFO: -- computing dual nodes\n",
      "2020-05-13 17:22:32,812 - root - INFO:     added 256 tri centroid nodes\n",
      "2020-05-13 17:22:32,814 - root - INFO:     added 48 boundary nodes\n",
      "2020-05-13 17:22:32,815 - root - INFO: -- Finding duplicates and ordering conn_cell_to_node\n",
      "2020-05-13 17:22:32,838 - root - INFO: -- removing duplicate nodes\n",
      "2020-05-13 17:22:32,841 - root - INFO: \n",
      "2020-05-13 17:22:32,842 - root - INFO: Elevating Triangulation to DEM\n",
      "2020-05-13 17:22:32,843 - root - INFO: ------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'elevation [m]')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contruct the dual mesh points, connectivity\n",
    "dual_points2, dual_conn, dual_from_primary = m2.to_dual()\n",
    "\n",
    "# elevate the dual\n",
    "dual_points3 = workflow.elevate(dual_points2, crs, dem, dem_profile)\n",
    "\n",
    "# construct the dual mesh\n",
    "m2_dual = workflow.mesh.Mesh2D(dual_points3.copy(), dual_conn)\n",
    "\n",
    "# plot the resulting surface mesh\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = workflow.plot.get_ax(crs, fig)\n",
    "\n",
    "#import matplotlib.cm\n",
    "primal_elev = np.array([mesh_points3[i,2] for i in dual_from_primary])\n",
    "#elev_cmap = workflow.colors.cm_mapper(primal_elev.min(), primal_elev.max(), matplotlib.cm.viridis)\n",
    "#m2_dual.plot(color=np.array([elev_cmap(e) for e in primal_elev]), ax=ax)\n",
    "\n",
    "workflow.plot.mesh(m2_dual, crs, ax=ax, color=primal_elev, facecolor='color', edgecolor='gray', linewidth=0.2)\n",
    "cbar = fig.colorbar(mp, orientation=\"horizontal\", pad=0.05)\n",
    "workflow.plot.hucs(coweeta, crs, ax=ax, color='k', linewidth=1)\n",
    "workflow.plot.rivers(rivers, crs, ax=ax, color='red', linewidth=1)\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "ax.set_title('elevation [m]')\n",
    "cbar.ax.set_title('elevation [m]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface properties\n",
    "\n",
    "Meshes interact with data to provide forcing, parameters, and more in the actual simulation.  Specifically, we need vegetation type on the surface to provide information about transpiration and subsurface structure to provide information about water retention curves, etc.\n",
    "\n",
    "We'll start by downloading and collecting land cover from the NLCD dataset, and generate sets for each land cover type that cover the surface.  Likely these will be some combination of grass, deciduous forest, coniferous forest, and mixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:33,239 - root - INFO: \n",
      "2020-05-13 17:22:33,240 - root - INFO: Preprocessing Raster\n",
      "2020-05-13 17:22:33,241 - root - INFO: ------------------------------\n",
      "2020-05-13 17:22:33,243 - root - INFO: collecting raster\n",
      "2020-05-13 17:22:33,250 - root - INFO: CRS: PROJCS[\"Albers_Conical_Equal_Area\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],TOWGS84[0,0,0,-0,-0,-0,0],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",29.5],PARAMETER[\"standard_parallel_2\",45.5],PARAMETER[\"latitude_of_center\",23],PARAMETER[\"longitude_of_center\",-96],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"meters\",1]]\n",
      "2020-05-13 17:22:33,290 - root - INFO: Found land cover dtypes: uint8\n",
      "2020-05-13 17:22:33,292 - root - INFO: Found land cover types: {41, 42, 43, 81, 21}\n"
     ]
    }
   ],
   "source": [
    "# download the NLCD raster\n",
    "lc_profile, lc_raster = workflow.get_raster_on_shape(sources['land cover'], \n",
    "                                                     coweeta.exterior(), crs)\n",
    "\n",
    "# resample the raster to the triangles\n",
    "lc = workflow.values_from_raster(m2_dual.centroids(), crs, lc_raster, lc_profile)\n",
    "\n",
    "# what land cover types did we get?\n",
    "logging.info('Found land cover dtypes: {}'.format(lc.dtype))\n",
    "logging.info('Found land cover types: {}'.format(set(lc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the NLCD data\n",
    "\n",
    "# -- get the NLCD colormap which uses official NLCD colors and labels\n",
    "nlcd_indices, nlcd_cmap, nlcd_norm, nlcd_ticks, nlcd_labels = \\\n",
    "                workflow.colors.generate_nlcd_colormap(lc)\n",
    "\n",
    "nlcd_labels_fw = []\n",
    "for label in nlcd_labels:\n",
    "    label_fw = label\n",
    "    if len(label) > 15:\n",
    "        if ' ' in label:\n",
    "            lsplit = label.split()\n",
    "            if len(lsplit) == 2:\n",
    "                label_fw = '\\n'.join(lsplit)\n",
    "            elif len(lsplit) == 4:\n",
    "                label_fw = '\\n'.join([' '.join(lsplit[0:2]),\n",
    "                                      ' '.join(lsplit[2:])])\n",
    "            elif len(lsplit) == 3:\n",
    "                if len(lsplit[0]) > len(lsplit[-1]):\n",
    "                    label_fw = '\\n'.join([lsplit[0],\n",
    "                                          ' '.join(lsplit[1:])])\n",
    "                else:\n",
    "                    label_fw = '\\n'.join([' '.join(lsplit[:-1]),\n",
    "                                          lsplit[-1]])\n",
    "    nlcd_labels_fw.append(label_fw)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = workflow.plot.get_ax(crs, fig)\n",
    "\n",
    "polys = workflow.plot.mesh(m2_dual, crs, ax=ax, color=lc, cmap=nlcd_cmap, norm=nlcd_norm, edgecolor='none', \n",
    "                                     facecolor='color', linewidth=0.5)\n",
    "mp = pcm.ScalarMappable(norm=nlcd_norm, cmap=nlcd_cmap)\n",
    "cb = fig.colorbar(mp)\n",
    "cb.set_ticks(nlcd_ticks)\n",
    "cb.set_ticklabels(nlcd_labels_fw)\n",
    "ax.set_title(\"land cover index\")\n",
    "fig.savefig('coweeta_nlcd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsurface properties\n",
    "\n",
    "Get soil structure from SSURGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:33,758 - root - INFO: \n",
      "2020-05-13 17:22:33,759 - root - INFO: Preprocessing Shapes\n",
      "2020-05-13 17:22:33,760 - root - INFO: ------------------------------\n",
      "2020-05-13 17:22:33,762 - root - INFO:   Using filename: /Users/uec/research/water/data/watershed-workflow/data-master/soil_survey/soil_survey_shape_-83.4790_35.0269_-83.4208_35.0743.gml\n",
      "2020-05-13 17:22:33,911 - root - INFO:   Found 460 shapes.\n",
      "2020-05-13 17:22:33,911 - root - INFO:   and crs: {'init': 'epsg:4326'}\n",
      "2020-05-13 17:22:34,042 - root - INFO: target bounds: (273971.0911428096, 3878839.6361173145, 279140.9150949494, 3883953.7853134344)\n",
      "2020-05-13 17:22:34,653 - root - INFO: shape union bounds: (272780.3245135138, 3877673.165081467, 281292.5015333445, 3887703.7251368817)\n",
      "2020-05-13 17:22:34,654 - root - INFO: Coloring shapes onto raster:\n",
      "2020-05-13 17:22:34,655 - root - INFO:   target_bounds = (273971.0911428096, 3878839.6361173145, 279140.9150949494, 3883953.7853134344)\n",
      "2020-05-13 17:22:34,656 - root - INFO:   out_bounds = [273966.0, 3878839.0, 279146.0, 3883959.0]\n",
      "2020-05-13 17:22:34,656 - root - INFO:   pixel_size = 10\n",
      "2020-05-13 17:22:34,657 - root - INFO:   width = 518, height = 512\n",
      "2020-05-13 17:22:34,658 - root - INFO:   and 43 independent colors of dtype int32\n"
     ]
    }
   ],
   "source": [
    "# download the NRCS soils data as shapes and project it onto the mesh\n",
    "import workflow.sources.manager_nrcs\n",
    "import matplotlib.cm\n",
    "\n",
    "# -- download the shapes\n",
    "target_bounds = coweeta.exterior().bounds\n",
    "_, soil_survey = workflow.get_shapes(sources['soil type'], target_bounds, crs)\n",
    "\n",
    "# -- log the bounds targetted and found\n",
    "logging.info('target bounds: {}'.format(target_bounds))\n",
    "logging.info('shape union bounds: {}'.format(\n",
    "    shapely.ops.cascaded_union(soil_survey).bounds))\n",
    "\n",
    "# -- determine the NRCS mukey for each soil unit; this uniquely identifies soil \n",
    "#    properties\n",
    "soil_ids = np.array([shp.properties['id'] for shp in soil_survey], np.int32)\n",
    "\n",
    "# -- color a raster by the polygons (this makes identifying a triangle's value much \n",
    "#    more efficient)\n",
    "soil_color_raster, soil_color_profile, img_bounds = \\\n",
    "            workflow.color_raster_from_shapes(target_bounds, 10, soil_survey,\n",
    "                                              soil_ids, crs)\n",
    "\n",
    "# -- resample the raster to the triangles\n",
    "soil_color = workflow.values_from_raster(m2_dual.centroids(), crs, \n",
    "                                         soil_color_raster, soil_color_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the soil data\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = workflow.plot.get_ax(crs, fig)\n",
    "\n",
    "mp = workflow.plot.mesh(m2_dual, crs, ax=ax, facecolor='color',\n",
    "                                 linewidth=0.5, color=soil_color, cmap='copper')\n",
    "ax.set_title('soil type index')\n",
    "\n",
    "fig.savefig('coweeta_soils')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh extrusion\n",
    "\n",
    "Given the surface mesh and material IDs on both the surface and subsurface, we can extrude the surface mesh in the vertical to make a 3D mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:22:35,666 - root - INFO: Cell summary:\n",
      "2020-05-13 17:22:35,667 - root - INFO: ------------------------------------------------------------\n",
      "2020-05-13 17:22:35,669 - root - INFO: l_id\t| c_id\t|mat_id\t| dz\t\t| z_top\n",
      "2020-05-13 17:22:35,670 - root - INFO: ------------------------------------------------------------\n",
      "2020-05-13 17:22:35,671 - root - INFO:  00 \t| 00 \t| 545806 \t|   0.050000 \t|   0.000000\n",
      "2020-05-13 17:22:35,672 - root - INFO:  01 \t| 01 \t| 545806 \t|   0.075796 \t|   0.050000\n",
      "2020-05-13 17:22:35,674 - root - INFO:  02 \t| 02 \t| 545806 \t|   0.114899 \t|   0.125796\n",
      "2020-05-13 17:22:35,675 - root - INFO:  03 \t| 03 \t| 545806 \t|   0.174177 \t|   0.240695\n",
      "2020-05-13 17:22:35,676 - root - INFO:  04 \t| 04 \t| 545806 \t|   0.264036 \t|   0.414872\n",
      "2020-05-13 17:22:35,676 - root - INFO:  05 \t| 05 \t| 545806 \t|   0.400255 \t|   0.678908\n",
      "2020-05-13 17:22:35,678 - root - INFO:  06 \t| 06 \t| 545806 \t|   0.606751 \t|   1.079163\n",
      "2020-05-13 17:22:35,681 - root - INFO:  07 \t| 07 \t| 545806 \t|   0.919781 \t|   1.685915\n",
      "2020-05-13 17:22:35,682 - root - INFO:  08 \t| 08 \t| 545806 \t|   1.394305 \t|   2.605695\n",
      "2020-05-13 17:22:35,683 - root - INFO:  09 \t| 09 \t| 545806 \t|   2.000000 \t|   4.000000\n",
      "2020-05-13 17:22:35,684 - root - INFO:  10 \t| 10 \t|  999 \t|   2.000000 \t|   6.000000\n",
      "2020-05-13 17:22:35,685 - root - INFO:  10 \t| 11 \t|  999 \t|   2.000000 \t|   8.000000\n",
      "2020-05-13 17:22:35,686 - root - INFO:  10 \t| 12 \t|  999 \t|   2.000000 \t|  10.000000\n",
      "2020-05-13 17:22:35,687 - root - INFO:  10 \t| 13 \t|  999 \t|   2.000000 \t|  12.000000\n",
      "2020-05-13 17:22:35,688 - root - INFO:  10 \t| 14 \t|  999 \t|   2.000000 \t|  14.000000\n",
      "2020-05-13 17:22:35,689 - root - INFO:  10 \t| 15 \t|  999 \t|   2.000000 \t|  16.000000\n",
      "2020-05-13 17:22:35,691 - root - INFO:  10 \t| 16 \t|  999 \t|   2.000000 \t|  18.000000\n",
      "2020-05-13 17:22:35,692 - root - INFO:  10 \t| 17 \t|  999 \t|   2.000000 \t|  20.000000\n",
      "2020-05-13 17:22:35,694 - root - INFO:  10 \t| 18 \t|  999 \t|   2.000000 \t|  22.000000\n",
      "2020-05-13 17:22:35,695 - root - INFO:  10 \t| 19 \t|  999 \t|   2.000000 \t|  24.000000\n",
      "2020-05-13 17:22:35,696 - root - INFO:  10 \t| 20 \t|  999 \t|   2.000000 \t|  26.000000\n",
      "2020-05-13 17:22:35,697 - root - INFO:  10 \t| 21 \t|  999 \t|   2.000000 \t|  28.000000\n",
      "2020-05-13 17:22:35,698 - root - INFO:  10 \t| 22 \t|  999 \t|   2.000000 \t|  30.000000\n",
      "2020-05-13 17:22:35,699 - root - INFO:  10 \t| 23 \t|  999 \t|   2.000000 \t|  32.000000\n",
      "2020-05-13 17:22:35,700 - root - INFO:  10 \t| 24 \t|  999 \t|   2.000000 \t|  34.000000\n",
      "2020-05-13 17:22:35,702 - root - INFO:  10 \t| 25 \t|  999 \t|   2.000000 \t|  36.000000\n",
      "2020-05-13 17:22:35,702 - root - INFO:  10 \t| 26 \t|  999 \t|   2.000000 \t|  38.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got telescoping factor: 1.515910144611108\n"
     ]
    }
   ],
   "source": [
    "# layer extrusion\n",
    "# -- data structures needed for extrusion\n",
    "layer_types = []\n",
    "layer_data = []\n",
    "layer_ncells = []\n",
    "layer_mat_ids = []\n",
    "z = 0.0\n",
    "\n",
    "# -- soil layer --\n",
    "#  top 6 m\n",
    "#  5 cm initial top cell\n",
    "#  10 cells\n",
    "#  expanding dz, growing with depth\n",
    "ncells = 9\n",
    "dz = 0.05\n",
    "layer_dz = 4\n",
    "\n",
    "tele = workflow.mesh.telescope_factor(ncells, dz, layer_dz)\n",
    "print(\"Got telescoping factor: {}\".format(tele))\n",
    "for i in range(ncells):\n",
    "    layer_types.append('constant')\n",
    "    layer_data.append(dz)\n",
    "    layer_ncells.append(1)\n",
    "    layer_mat_ids.append(soil_color)\n",
    "    z += dz\n",
    "    dz *= tele\n",
    "    \n",
    "# one more 2m layer makes 6m\n",
    "dz = 2.0\n",
    "layer_types.append('constant')\n",
    "layer_data.append(dz)\n",
    "layer_ncells.append(1)\n",
    "layer_mat_ids.append(soil_color)\n",
    "z += dz\n",
    "\n",
    "# -- geologic layer --\n",
    "# keep going for 2m cells until we hit the bottom of\n",
    "# the domain\n",
    "layer_types.append(\"constant\")\n",
    "layer_data.append(40 - z) # depth of bottom of domain is 40 m\n",
    "layer_ncells.append(int(round(layer_data[-1] / dz)))\n",
    "layer_mat_ids.append(999*np.ones_like(soil_color))\n",
    "\n",
    "# print the summary\n",
    "workflow.mesh.Mesh3D.summarize_extrusion(layer_types, layer_data, \n",
    "                                            layer_ncells, layer_mat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrude\n",
    "m3 = workflow.mesh.Mesh3D.extruded_Mesh2D(m2_dual, layer_types, layer_data, \n",
    "                                             layer_ncells, layer_mat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back on land cover side sets\n",
    "surf_ss = m3.side_sets[1]\n",
    "\n",
    "for index, name in zip(nlcd_indices, nlcd_labels):\n",
    "    where = np.where(lc == index)[0]\n",
    "    ss = workflow.mesh.SideSet(name, int(index), \n",
    "                            [surf_ss.elem_list[w] for w in where],\n",
    "                            [surf_ss.side_list[w] for w in where])        \n",
    "    m3.side_sets.append(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are using exodus.py v 1.13 (seacas-beta), a python wrapper of some of the exodus library.\n",
      "\n",
      "Copyright (c) 2013, 2014, 2015, 2016, 2017, 2018, 2019 National Technology &\n",
      "Engineering Solutions of Sandia, LLC (NTESS).  Under the terms of\n",
      "Contract DE-NA0003525 with NTESS, the U.S. Government retains certain\n",
      "rights in this software.\n",
      "\n",
      "Opening exodus file: coweeta_basin_dual.exo\n",
      "Closing exodus file: coweeta_basin_dual.exo\n"
     ]
    }
   ],
   "source": [
    "# save to disk\n",
    "try:\n",
    "    os.remove('coweeta_basin_dual.exo')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "m3.write_exodus('coweeta_basin_dual.exo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jigsawpy\n",
    "from matplotlib.collections import LineCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = jigsawpy.jigsaw_jig_t()\n",
    "geom = jigsawpy.jigsaw_msh_t()\n",
    "mesh = jigsawpy.jigsaw_msh_t()\n",
    "\n",
    "geom.mshID = \"euclidean-mesh\"\n",
    "geom.ndims = +2\n",
    "geom.vert2 = np.array([(tuple(c[0:2]), 0) for c in m2.coords], \n",
    "        dtype=geom.VERT2_t)\n",
    "\n",
    "geom.edge2 = np.array([(e,0) for e in m2.edges()],\n",
    "        dtype=geom.EDGE2_t)\n",
    "\n",
    "opts.mesh_dims = +2                 # 2-dim. simplexes\n",
    "jigsawpy.lib.jigsaw(opts, geom, mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 641, 1089],\n",
       "       [ 536,  883],\n",
       "       [ 364,  531],\n",
       "       ...,\n",
       "       [ 191,  848],\n",
       "       [ 679,  875],\n",
       "       [ 707, 1365]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.edge2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(jmesh):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)  ax.triplot(jmesh.point['coord'][:,0], jmesh.point['coord'][:,1], jmesh.tria3['index'])\n",
    "    plt.show()\n",
    "    #segs = np.array([jmesh.point['coord'][e] for e in jmesh.tria3['index']])\n",
    "    #print(segs.shape)\n",
    "    #lc = LineCollection(segs)\n",
    "\n",
    "    #ax.add_collection(lc)\n",
    "    #ax.set_xlim(segs[:,:,0].min(), segs[:,:,0].max())\n",
    "    #ax.set_ylim(segs[:,:,1].min(), segs[:,:,1].max())\n",
    "\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import workflow.triangulation\n",
    "\n",
    "# alternative -- triangulate with jigsaw\n",
    "segments = list(coweeta.segments)\n",
    "segments = segments + list(workflow.river_tree.forest_to_list(rivers))\n",
    "print(len(segments))\n",
    "nodes_edges = workflow.triangulation.NodesEdges(segments)\n",
    "nodes_edges.check(tol=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes_edges.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = jigsawpy.jigsaw_jig_t()\n",
    "geom = jigsawpy.jigsaw_msh_t()\n",
    "mesh = jigsawpy.jigsaw_msh_t()\n",
    "\n",
    "geom.mshID = \"euclidean-mesh\"\n",
    "geom.ndims = +2\n",
    "geom.vert2 = np.array([(tuple(n), 0) for n in nodes_edges.nodes], \n",
    "        dtype=geom.VERT2_t)\n",
    "\n",
    "geom.edge2 = np.array([(e,0) for e in nodes_edges.edges],\n",
    "        dtype=geom.EDGE2_t)\n",
    "\n",
    "\n",
    "opts.mesh_kern = \"delfront\"         # DELAUNAY kernel\n",
    "opts.hfun_hmax = 0.05               # push HFUN limits\n",
    "opts.mesh_dims = +2                 # 2-dim. simplexes\n",
    "opts.optm_qlim = +.95\n",
    "opts.mesh_top1 = True               # for sharp feat's\n",
    "opts.geom_feat = True\n",
    "\n",
    "\n",
    "\n",
    "jigsawpy.lib.jigsaw(opts, geom, mesh)\n",
    "\n",
    "#scr2 = jigsawpy.triscr2(            # \"quality\" metric\n",
    "#        mesh.point[\"coord\"],\n",
    "#        mesh.tria3[\"index\"])\n",
    "\n",
    "#jigsawpy.savevtk(\"coweeta_jigsaw.vtk\", mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([k for k in mesh.__dict__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mesh.slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import scipy.spatial\n",
    "\n",
    "# get coords in 2D\n",
    "coords = m2.coords[:,0:2]\n",
    "eps = 0.1\n",
    "\n",
    "point = collections.namedtuple('Point', ['x', 'y'])\n",
    "\n",
    "def circumcenter(coord1,coord2,coord3):  # {{{\n",
    "    p1 = point(*coord1)\n",
    "    p2 = point(*coord2)\n",
    "    p3 = point(*coord3)\n",
    "\n",
    "    d = 2 * (p1.x * (p2.y - p3.y) + p2.x *\n",
    "                (p3.y - p1.y) + p3.x * (p1.y - p2.y))\n",
    "\n",
    "    xv = ((p1.x**2 + p1.y**2) * (p2.y - p3.y) + (p2.x**2 + p2.y**2)\n",
    "          * (p3.y - p1.y) + (p3.x**2 + p3.y**2) * (p1.y - p2.y)) / d\n",
    "    yv = ((p1.x**2 + p1.y**2) * (p3.x - p2.x) + (p2.x**2 + p2.y**2)\n",
    "          * (p1.x - p3.x) + (p3.x**2 + p3.y**2) * (p2.x - p1.x)) / d\n",
    "\n",
    "    return (xv, yv)\n",
    "\n",
    "# collection of all dual nodes given by:\n",
    "# - primal nodes on the boundary\n",
    "# - primal edge midpoits on the boundary (note this length is the same as primal nodes on the boundary)\n",
    "# - primal cell circumcenters?\n",
    "boundary_edges = m2.boundary_edges()\n",
    "logging.info(\"computed boundary edges\")\n",
    "n_tot = len(m2.conn) + 2*len(boundary_edges)\n",
    "logging.info(\"  n_primal_cell = {}, n_boundary_edges = {}, n_total_dual_nodes = \"\n",
    "             \"{}\".format(len(m2.conn), len(boundary_edges), n_tot))\n",
    "dual_nodes = np.zeros((n_tot, 2), 'd')\n",
    "dual_cells = [list() for i in range(len(coords))]\n",
    "\n",
    "is_boundary = np.zeros(len(dual_cells), 'i')\n",
    "\n",
    "#\n",
    "# Loop over all primal cells (triangles), adding the circumcenter \n",
    "# as a dual node and sticking that node in three dual cells rooted\n",
    "# at the three primal nodes.\n",
    "#  \n",
    "i_dual_node = 0\n",
    "for j, c in enumerate(m2.conn):\n",
    "    dual_nodes[i_dual_node][:] = circumcenter(coords[c[0]], coords[c[1]], coords[c[2]])\n",
    "    dual_cells[c[0]].append(i_dual_node)\n",
    "    dual_cells[c[1]].append(i_dual_node)\n",
    "    dual_cells[c[2]].append(i_dual_node)\n",
    "    i_dual_node += 1\n",
    "  \n",
    "logging.info(\"added tri centroid nodes ({})\".format(i_dual_node)) \n",
    "\n",
    "#\n",
    "# Loop over the boundary, adding both the primal nodes as dual nodes \n",
    "# and the edge midpoints as dual nodes.\n",
    "#\n",
    "# Add the primal node and two midpoints on either side to the list \n",
    "# of dual nodes in the cell \"rooted at\" the primal node.\n",
    "#\n",
    "for i, e in enumerate(boundary_edges):\n",
    "    # add the primal node always\n",
    "    my_dual_node = i_dual_node\n",
    "    dual_nodes[i_dual_node][:] = coords[e[0]]\n",
    "    i_dual_node += 1\n",
    "\n",
    "    my_cell = list()\n",
    "\n",
    "    # stick in the previous midpoint node\n",
    "    if i is 0:\n",
    "        ugh_point = e[0]\n",
    "        my_cell.append(-1)\n",
    "    else:\n",
    "        my_cell.append(prev_midp_n)\n",
    "\n",
    "    # stick in the next midpoint node, if it isn't too close\n",
    "    next_midp = (coords[e[0]][:] + coords[e[1]][:])/2.\n",
    "    next_midp_n = i_dual_node\n",
    "    for n in dual_cells[e[0]]:\n",
    "        if np.linalg.norm(dual_nodes[n] - next_midp) < eps:\n",
    "            next_midp_n = n\n",
    "            break\n",
    "    if next_midp_n == i_dual_node:\n",
    "        dual_nodes[i_dual_node][:] = next_midp\n",
    "        i_dual_node += 1\n",
    "    \n",
    "    my_cell.append(next_midp_n)\n",
    "    my_cell.append(my_dual_node)\n",
    "    dual_cells[e[0]].extend(my_cell)\n",
    "    is_boundary[e[0]] = 1\n",
    "    prev_midp_n = next_midp_n\n",
    "    \n",
    "assert(dual_cells[ugh_point][-3] == -1)\n",
    "dual_cells[ugh_point][-3] = prev_midp_n\n",
    "logging.info(\"added boundary nodes\") \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Now every dual cell has a list of nodes, and the dual coordinates are done.\n",
    "#\n",
    "# Must still order the nodes in each dual cell\n",
    "#\n",
    "for i in range(len(dual_cells)):\n",
    "    c = dual_cells[i]\n",
    "    \n",
    "    if is_boundary[i]:\n",
    "        # may not be convex -- triangulate\n",
    "        c_orig = c[:]\n",
    "        c0 = c[-1]\n",
    "        cdn = c[-3]\n",
    "        cup = c[-2]\n",
    "        \n",
    "        cell_coords = np.array([dual_nodes[i] for i in c[:-1]]) - dual_nodes[c0]\n",
    "        angle = np.array([np.arctan2(cell_coords[j,1], cell_coords[j,0]) for j in range(len(cell_coords))])\n",
    "        order = np.argsort(angle)\n",
    "        c = [c[j] for j in order]\n",
    "        up_i = c.index(cup)\n",
    "        dn_i = c.index(cdn)\n",
    "        \n",
    "        if dn_i == (up_i + 1)%len(c):\n",
    "            cn = c[dn_i:] + c[0:dn_i]\n",
    "        elif up_i == (dn_i + 1)%len(c):\n",
    "            cn = c[up_i:] + c[0:up_i]\n",
    "        else:\n",
    "            print(\"Uh oh borked geom: up_i = {}, dn_i = {}, c = {}\".format(up_i, dn_i, c))\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "            cc_sorted = np.array([cell_coords[k] for k in order]) + dual_nodes[c0]\n",
    "            ax.plot(cc_sorted[:,0], cc_sorted[:,1], 'k-x')            \n",
    "            ax.scatter(dual_nodes[c0,0], dual_nodes[c0,1], color='r')\n",
    "            ax.scatter(dual_nodes[cup,0], dual_nodes[cup,1], color='m')\n",
    "            ax.scatter(dual_nodes[cdn,0], dual_nodes[cdn,1], color='b')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            fig = plt.figure(figsize=figsize)\n",
    "            ax = workflow.plot.get_ax(crs, fig)\n",
    "\n",
    "            mp = workflow.plot.triangulation(mesh_points3, mesh_tris, crs, ax=ax, \n",
    "                                 color='elevation', edgecolor='white', linewidth=0.4)\n",
    "            cbar = fig.colorbar(mp, orientation=\"horizontal\", pad=0.05)\n",
    "            workflow.plot.hucs(coweeta, crs, ax=ax, color='k', linewidth=1)\n",
    "            workflow.plot.shply([shapely.geometry.LineString(cc_sorted),], crs, ax=ax, color='red', linewidth=1)\n",
    "            ax.set_aspect('equal', 'datalim')\n",
    "            \n",
    "            raise RuntimeError('uh oh borked geom')\n",
    "        \n",
    "        #print('Boundary: c_orig = {}, c = {}, cn = {}'.format(c_orig, c, cn))\n",
    "        for k in range(len(cn)-1):\n",
    "            if k == 0:\n",
    "                dual_cells[i] = [c0, cn[k+1], cn[k]]\n",
    "            else:\n",
    "                dual_cells.append([c0, cn[k+1], cn[k]])\n",
    "                \n",
    "    else:   \n",
    "        cell_coords = np.array([dual_nodes[i] for i in c])\n",
    "        cell_centroid = cell_coords.mean(axis=0)\n",
    "        cell_coords = cell_coords - cell_centroid\n",
    "\n",
    "        angle = np.array([np.arctan2(cell_coords[j,1], cell_coords[j,0]) for j in range(len(cell_coords))])\n",
    "        order = np.argsort(angle)\n",
    "        dual_cells[i] = [c[j] for j in order]\n",
    "    \n",
    "logging.info(\"sorted nodes\")\n",
    " \n",
    "dual_points3 = workflow.elevate(dual_nodes[:,0:2], crs, dem, dem_profile)\n",
    "logging.info(\"elevated dual\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_dual = workflow.extrude.Mesh2D(dual_points3.copy(), dual_cells)\n",
    "m2_dual.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ats_meshing_20190719]",
   "language": "python",
   "name": "conda-env-ats_meshing_20190719-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
